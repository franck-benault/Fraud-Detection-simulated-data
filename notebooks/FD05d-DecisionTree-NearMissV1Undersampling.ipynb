{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284b6b6-2e80-4390-8492-c443f8d2b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see link\n",
    "# https://github.com/Fraud-Detection-Handbook\n",
    "\n",
    "package ='05-sklearn.tree'\n",
    "name='Decision Tree'\n",
    "tuningAndParameters='05-NearMissV1 Undersampling'\n",
    "\n",
    "hyperparametersFound={'criterion': 'gini', 'max_depth': 11, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
    "scalerFound='MinMaxScaler'\n",
    "n_neighborsFound=6\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b8f02-9b56-4c4f-9200-4463caae2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "fpath = os.path.join('..//scripts')\n",
    "sys.path.append(fpath)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#loading internal scripts\n",
    "import datamanagement as dm\n",
    "reload(dm)\n",
    "\n",
    "import result as resultMd\n",
    "reload(resultMd)\n",
    "\n",
    "import graph as gf\n",
    "reload(gf)\n",
    "\n",
    "import scaler as scaler\n",
    "reload(scaler)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b6bf1-3a6b-44ba-9a13-35d09453300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLearning, dfValidation =dm.getDataLearningAndValidation()\n",
    "\n",
    "dfLearning.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a84d93-f5fc-445d-a4d6-d0251aeec153",
   "metadata": {},
   "source": [
    "# search n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f4215-1c21-4549-bee9-80389c6075ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_f1s=[]\n",
    "test_f1s =[]\n",
    "range= []\n",
    "\n",
    "predictors = dm.getPredictors(dfLearning)\n",
    "target = dm.getTarget()\n",
    "\n",
    "x1, y1 = dfLearning[predictors], dfLearning[target]\n",
    "sc = scaler.getScaler(scalerFound)\n",
    "x2 = sc.fit_transform(x1)\n",
    "\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "\n",
    "x_train0, x_test, y_train0, y_test = train_test_split(x2, y1, test_size = TEST_SIZE, \n",
    "                                                        stratify=y1,\n",
    "                                                        random_state = RANDOM_STATE)\n",
    "\n",
    "neighbors = np.arange(1,12,1)\n",
    "for n_neighbors in neighbors:\n",
    "    print(\"n_neighbors \",n_neighbors)\n",
    "    undersample = NearMiss(sampling_strategy=0.01,version=1, n_neighbors=n_neighbors)\n",
    "    x3, y3 = undersample.fit_resample(x2,y1)\n",
    "    x_train, y_train = undersample.fit_resample(x_train0, y_train0)\n",
    "\n",
    "    modelClf = DecisionTreeClassifier(random_state=42)\n",
    "    parameters=hyperparametersFound\n",
    "    modelClf.set_params(**parameters)\n",
    "\n",
    "    modelClf.fit(x_train, y_train)\n",
    "    predsTrain = modelClf.predict(x_train)\n",
    "    predsTest = modelClf.predict(x_test)\n",
    "\n",
    "    train_f1=f1_score(y_train, predsTrain)\n",
    "    print(\"f1 train {:.4f}\".format(train_f1))\n",
    "    \n",
    "    test_f1=f1_score(y_test, predsTest)\n",
    "    print(\"f1 test  {:.4f}\".format(test_f1))\n",
    "    \n",
    "    train_f1s.append(train_f1)\n",
    "    test_f1s.append(test_f1)\n",
    "    range.append(n_neighbors)\n",
    "    print('-----------------------')\n",
    "\n",
    "dm.plt_train_test(range, train_f1s, \"train\", test_f1s,\" test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bf800-9514-48d6-b5ae-ce4e81267ef4",
   "metadata": {},
   "source": [
    "# Scaling choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a4c60-171c-4b71-86ce-a44f24ffbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "predictors = dm.getPredictors(dfLearning)\n",
    "target = dm.getTarget()\n",
    "\n",
    "scalers = scaler.getScalers()\n",
    "for key in scalers:\n",
    "    print(key)\n",
    "    x1, y1 = dfLearning[predictors], dfLearning[target]\n",
    "    sc=scalers.get(key)\n",
    "    x2 = sc.fit_transform(x1)\n",
    "\n",
    "    TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "    RANDOM_STATE = 0\n",
    "\n",
    "\n",
    "    x_train0, x_test, y_train0, y_test = train_test_split(x2, y1, test_size = TEST_SIZE, \n",
    "                                                        stratify=y1,\n",
    "                                                        random_state = RANDOM_STATE)\n",
    "\n",
    "    undersample = NearMiss(sampling_strategy=0.01,version=1, n_neighbors=n_neighborsFound)\n",
    "    x3, y3 = undersample.fit_resample(x2,y1)\n",
    "    x_train, y_train = undersample.fit_resample(x_train0, y_train0)\n",
    "    \n",
    "    modelClf = DecisionTreeClassifier(random_state=42)\n",
    "    parameters=hyperparametersFound\n",
    "    modelClf.set_params(**parameters)\n",
    "\n",
    "    modelClf.fit(x_train, y_train)\n",
    "    predsTrain = modelClf.predict(x_train)\n",
    "    predsTest = modelClf.predict(x_test)\n",
    "\n",
    "    train_f1=f1_score(y_train, predsTrain)\n",
    "    print(\"f1 train {:.4f}\".format(train_f1))\n",
    "    \n",
    "    test_f1=f1_score(y_test, predsTest)\n",
    "    print(\"f1 test  {:.4f}\".format(test_f1))\n",
    "    print('-----------------------')\n",
    "\n",
    "#MinMaxScaler\n",
    "#f1 train 0.7765\n",
    "#f1 test  0.7163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a72b0a-f112-4352-a9ee-5865d75a9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "predictors = dm.getPredictors(dfLearning)\n",
    "target = dm.getTarget()\n",
    "\n",
    "x1, y1 = dfLearning[predictors], dfLearning[target]\n",
    "sc = scaler.getScaler(scalerFound)\n",
    "x2 = sc.fit_transform(x1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train0, x_test, y_train0, y_test = train_test_split(x2, y1, test_size = TEST_SIZE, \n",
    "                                                        stratify=y1,\n",
    "                                                        random_state = RANDOM_STATE)\n",
    "\n",
    "\n",
    "undersample = NearMiss(sampling_strategy=0.01,version=1, n_neighbors=n_neighborsFound)\n",
    "x3, y3 = undersample.fit_resample(x2,y1)\n",
    "x_train, y_train = undersample.fit_resample(x_train0, y_train0)\n",
    "print(x_train0.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4676a2-bd81-4ab8-8479-924511c35cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#{'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 32\n",
    "dic_param={\n",
    "    'criterion':[\"gini\",\"entropy\"],\n",
    "    'max_depth': randint(2,12),\n",
    "    'min_samples_leaf': randint(2,10),\n",
    "    'min_samples_split': randint(10,20)\n",
    "}\n",
    "modelClf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(modelClf,dic_param, scoring='f1', verbose=10,cv=4).fit(x_train, y_train)\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)\n",
    "\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 17}\n",
    "#0.6993891336747396\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18a47c-076e-43d1-ba38-57273e27a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#{'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 7, 'min_samples_split': 32\n",
    "dic_param={\n",
    "    'criterion':[\"gini\",\"entropy\"],\n",
    "    'max_depth': [3,4,5,6,7,8,9,10,11,12],\n",
    "    'min_samples_leaf': [3,4,5,6,7,8,9],\n",
    "    'min_samples_split': [3,4,5,6,7,8,9,10,12]\n",
    "}\n",
    "modelClf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "random_search = GridSearchCV(modelClf,dic_param, scoring='f1', verbose=10,cv=4).fit(x_train, y_train)\n",
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 7, 'min_samples_split': 17}\n",
    "#0.6993891336747396\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 18}\n",
    "#0.7146429823176678\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
    "#0.7291975197990105\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 12}\n",
    "#0.7086074227602854\n",
    "\n",
    "#{'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 7}\n",
    "#0.7066416843459545\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 11, 'min_samples_leaf': 7, 'min_samples_split': 3}\n",
    "#0.7144743888318015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc275cd-7f0d-4497-9139-56ae2e0b21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from datetime import datetime\n",
    "\n",
    "modelClf = DecisionTreeClassifier(random_state=42)\n",
    "parameters=hyperparametersFound\n",
    "\n",
    "modelClf.set_params(**parameters)\n",
    "then= datetime.now()\n",
    "modelClf.fit(x_train, y_train)\n",
    "now = datetime.now()\n",
    "duration= now - then\n",
    "duration_in_s = duration.total_seconds()\n",
    "print(\"Duration \",duration_in_s)\n",
    "resultMd.update_time_response_result(package, name, tuningAndParameters, duration_in_s)\n",
    "\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "F1Learning =f1_score(y_train, predsTrain)\n",
    "F1Test=f1_score(y_test, predsTest)\n",
    "dm.show_confusion_matrix(y_train, predsTrain,'Confusion matrix learning data')\n",
    "print(f\"f1 train {F1Learning:.3f}\")\n",
    "dm.show_confusion_matrix(y_test, predsTest,'Confusion matrix test data')\n",
    "print(f\"f1 test {F1Test:.3f}\")\n",
    "resultMd.update_learning_test_result(package, name, tuningAndParameters, F1Learning,F1Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3219beb-c74a-4a18-867e-71d33001bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.show_importance(modelClf, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c143721-b0a3-4a04-acf8-b6fc710f000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.show_prediction_graph(modelClf, x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7745d-35e7-4d7b-83a8-27c8df586493",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfValidatationScaled = sc.transform(dfValidation[predictors])\n",
    "\n",
    "predsValidation = modelClf.predict(dfValidatationScaled)\n",
    "f1=f1_score(dfValidation[target], predsValidation)\n",
    "\n",
    "\n",
    "dm.show_confusion_matrix(dfValidation[target], predsValidation,'Confusion matrix validation data')\n",
    "print(f\"f1 validation {f1:.3f}\")\n",
    "resultMd.update_performance_result(package, name, tuningAndParameters, f1)\n",
    "resultMd.update_hyperparameters_result(package, name, tuningAndParameters, hyperparametersFound,scalerFound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ddb3e5-5f2d-485e-a3e6-623537ca6f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
